{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9415/10000 (94%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 47833/60000 (80%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9639/10000 (96%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 57018/60000 (95%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9700/10000 (97%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 57821/60000 (96%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9730/10000 (97%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58190/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9756/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58403/60000 (97%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9782/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58539/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9798/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58634/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9812/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58748/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9801/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58823/60000 (98%)\n",
      "\n",
      "\n",
      "Test set: Accuracy: 9828/10000 (98%)\n",
      "\n",
      "\n",
      "Train set:  Accuracy: 58875/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "# TODO:define model\n",
    "  def __init__(self):\n",
    "    super(SimpleNet, self).__init__()\n",
    "    # 输入1通道，输出10通道，kernel 5*5\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.mp = nn.MaxPool2d(2)\n",
    "    # fully connect\n",
    "    self.fc = nn.Linear(320, 10)\n",
    " \n",
    "  def forward(self, x):\n",
    "    # in_size = 64\n",
    "    in_size = x.size(0) # one batch\n",
    "    # x: 64*10*12*12\n",
    "    x = F.relu(self.mp(self.conv1(x)))\n",
    "    # x: 64*20*4*4\n",
    "    x = F.relu(self.mp(self.conv2(x)))\n",
    "    # x: 64*320\n",
    "    x = x.view(in_size, -1) # flatten the tensor\n",
    "    # x: 64*10\n",
    "    x = self.fc(x)\n",
    "    return F.log_softmax(x)\n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TODO:forward + backward + optimize\n",
    "    train_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = torch.max(output.data,1)[1]\n",
    "        train_correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        pred = torch.max(output.data,1)[1]\n",
    "        test_correct += pred.eq(target.data.view_as(pred)).cpu().sum()  \n",
    "        \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_correct, len(test_loader.dataset),\n",
    "    100. * test_correct / len(test_loader.dataset)))\n",
    "    print('\\nTrain set:  Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    train_correct, len(train_loader.dataset),\n",
    "    100. * train_correct / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
